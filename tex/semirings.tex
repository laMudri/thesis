\chapter{Usage restriction via semirings}\label{sec:semirings}

The methods described in \cref{sec:simple} for the simply typed
$\lambda$-calculus
make crucial use of \emph{weakening} --- the fact that if we have
$\Gamma \vdash A$, then we also have $\Gamma, \Delta \vdash A$.
We use this property to update environments as we take them under binders.
However, as we saw in \cref{sec:linearity}, there are interesting calculi in
which general weakening does not hold.
As such, one of the aims of this chapter will be to find a form of weakening
applicable to variables of any type, while essentially retaining linearity
(as opposed to affineness).

As explained by \citet{McBride16}, the first insight is to, instead of
removing variables from the context of certain subterms, add an annotation to
free variables saying whether or not they are to be used.
I use an annotation $\gr0$ on variables that are not to be used, and an
annotation $\gr1$ on variables that are to be used.
This convention lets us transcribe the usual $\otimes$-introduction rule
(below left) as a rule with usage annotations (below right).
In the notation on the right, I let $\Gamma = \grP\gamma$ and
$\Delta = \grQ\delta$, where $\Gamma$ is a whole context comprising a
\emph{usage context} $\grP$ and a \emph{typing context} $\gamma$.
A usage context is a list of usage annotations, so
$\grP = \gr{r_1}, \ldots, \gr{r_m}$ and a typing context is a list of types, so
$\gamma = A_1, \ldots, A_m$.
When combined, the usage context and the typing context will be of the same
length.
Explicit contexts will usually be written with usage annotations and types
interspersed, as $\gr{r_1}A_1, \ldots, \gr{r_m}A_m$.
I use $\gr r\gamma$ to abbreviate $\gr rx_1, \ldots, \gr rx_m$.

\[
  \ebrule{%
    \hypo{\Gamma \vdash A}
    \hypo{\Delta \vdash B}
    \infer2{\Gamma, \Delta \vdash A \otimes B}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \hypo{\gr1\gamma, \gr0\delta \vdash A}
    \hypo{\gr0\gamma, \gr1\delta \vdash B}
    \infer2{\gr1\gamma, \gr1\delta \vdash A \otimes B}
  }
\]

The eventual target of all these $\gr0$-annotated variables is the variable
rule, which I transcribe as follows.
The $\gr1$ shows us that we can use the variable thus annotated, while the
$\gr0$s let us discard all of the other variables in $\gamma$.

\[
  \ebrule{%
    \infer0{A \vdash A}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \infer0{\gr0\gamma, \gr1A \vdash A}
  }
\]

The use of $\gr0$ gives us the property that variables never go out of
scope in subterms; rather, we lose the ability to use certain variables, but
retain the ability to refer to them metatheoretically.
Additionally, we recover a form of weakening: if $\Gamma \vdash A$, then also
$\Gamma, \gr0\delta \vdash A$, because the resulting term indeed uses no
variables from $\delta$.
I prove the admissibility of weakening for terms will come in \cref{sec:lrsub}.

If we follow the DILL style of variable management explained in \cref{sec:dill},
there are not just the two
states \emph{to be used} ($\gr1$) and \emph{not to be used} ($\gr0$), but also
\emph{usable unrestrictedly}.
If we assign unrestricted (or \emph{intuitionistic}) variables an annotation
$\gr\omega$, we can make the following transcription of the DILL
$\otimes$-introduction rule.

\[
  \ebrule{%
    \hypo{\Theta; \Gamma \vdash A}
    \hypo{\Theta; \Delta \vdash B}
    \infer2{\Theta; \Gamma, \Delta \vdash A \otimes B}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \hypo{\gr\omega\theta, \gr1\gamma, \gr0\delta \vdash A}
    \hypo{\gr\omega\theta, \gr0\gamma, \gr1\delta \vdash B}
    \infer2{\gr\omega\theta, \gr1\gamma, \gr1\delta \vdash A \otimes B}
  }
\]

To conceptualise the criteria on the usage annotations involved in this rule,
I introduce an additive structure over usage annotations.
The rule stated above relies on the facts that $\gr1 + \gr0 = \gr1$,
$\gr0 + \gr1 = \gr1$, and $\gr\omega + \gr\omega = \gr\omega$.
Addition lifts pointwise to vectors of usage annotations (the green capital
calligraphic $\grP$, $\grQ$, and $\grR$).
A beneficial side-effect of the fact that $\gr0 + \gr0 = \gr0$ is that the
rule on the right below is actually more general, and accepts $\gr0$-annotated
variables in its
conclusion, which is essential for weakening to be admissible.

\[
  \ebrule{%
    \hypo{\gr\omega\theta, \gr1\gamma, \gr0\delta \vdash A}
    \hypo{\gr\omega\theta, \gr0\gamma, \gr1\delta \vdash B}
    \infer2{\gr\omega\theta, \gr1\gamma, \gr1\delta \vdash A \otimes B}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \hypo{\grR = \grP + \grQ}
    \hypo{\grP\gamma \vdash A}
    \hypo{\grQ\gamma \vdash B}
    \infer3{\grR\gamma \vdash A \otimes B}
  }
\]

Some other transcriptions from DILL to the usage annotation style are as
follows.
I unify the variable rules (the one for linear variables and the one for
intuitionistic variables) by introducing a coercibility ordering $\leq$ on usage
annotations.
We have $\gr\omega \leq \gr1$ because an intuitionistic variable can fill the
demand of a linear variable by dereliction.
We also have $\gr\omega \leq \gr0$, because intuitionistic variables can be
weakened away like $\gr0$-annotated variables.
This ordering information is shown in the diagram
\begin{tikzpicture}[baseline]
  \node(omega) at (0,0) {$\gr\omega$};
  \node(0) [above left of=omega] {$\gr0$};
  \node(1) [above right of=omega] {$\gr1$};

  \draw (omega) -- (0);
  \draw (omega) -- (1);
\end{tikzpicture}.
All together, this means that at the (only) variable rule, the variable being
used must have annotation less than or equal to $\gr1$, and every other variable
must have annotation less than or equal to $\gr0$.
I write this requirement as $\grR \leq \langle x \rvert$, where
$\langle x \rvert$ is the \emph{basis vector} at position $x$.

\[
  \ebrule{%
    \infer0{\Theta; A \vdash A}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \infer0{\gr\omega\theta, \gr1A, \gr0\delta \vdash A}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \hypo{\grR \leq \bra x}
    \hypo{\gamma_x = A}
    \infer2{\grR\gamma \vdash A}
  }
\]

\[
  \ebrule{%
    \infer0{\Theta, A; {\cdot} \vdash A}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \infer0{\gr\omega\theta, \gr\omega A, \gr0\delta \vdash A}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \hypo{\grR \leq \bra x}
    \hypo{\gamma_x = A}
    \infer2{\grR\gamma \vdash A}
  }
\]

The final interesting rule form to cover is found in DILL's
$\oc$-introduction rule.
DILL's $\oc$-introduction can be though of as an $\gr\omega$-ary counterpart to
$\otimes$-introduction, though with the same premise each time rather than
$\gr\omega$-many premises.
This explains why only $\gr\omega$- and
$\gr0$-annotated variables can appear in the conclusion of $\oc$-introduction,
and also justifies the choice below of multiplication (vector scaling) as the
algebraic operation controlling the $\oc$-modality.

\[
  \ebrule{%
    \hypo{\Theta; {\cdot} \vdash A}
    \infer1{\Theta; {\cdot} \vdash \oc A}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \hypo{\gr\omega\theta, \gr0\delta \vdash A}
    \infer1{\gr\omega\theta, \gr0\delta \vdash \oc A}
  }
  \quad\rightsquigarrow\quad
  \ebrule{%
    \hypo{\grR \leq \gr\omega\grP}
    \hypo{\grP\gamma \vdash A}
    \infer2{\grR\gamma \vdash \oc_{\gr\omega} A}
  }
\]

In summary, the structure we have required of the set of usage annotations is
that they have addition (for $\otimes$-introduction and similar rules),
multiplication (for $\oc$-introduction), a $1$ (for a variable being used), a
$0$ (for a variable not being used), and an ordering (allowing for subsumption
of usage restrictions).
Together, these form a \emph{partially ordered semiring} (posemiring), the laws
of which are both supported by examples and necessary for the syntax to be well
behaved.
%\todo{Refer back to preliminaries for definition of posemiring}
For concreteness, I collect together the definition of the
$\{\gr0, \gr1, \gr\omega\}$ posemiring I have been using so far.

\begin{example}\label{def:lin-semiring}
  The \emph{$\{\gr0, \gr1, \gr\omega\}$ posemiring}, also known as the
  \emph{linearity posemiring}, has the operations given as follows, with
  $0 \coloneqq \gr0$ and $1 \coloneqq \gr1$:

  \makebox[\textwidth][s]{
    \begin{tabular}{c|ccc}
      $+$ & $\gr0$ & $\gr1$ & $\gr\omega$ \\ \hline
      $\gr0$ & $\gr0$ & $\gr1$ & $\gr\omega$ \\
      $\gr1$ & $\gr1$ & $\gr\omega$ & $\gr\omega$ \\
      $\gr\omega$ & $\gr\omega$ & $\gr\omega$ & $\gr\omega$ \\
    \end{tabular}
    \begin{tabular}{c|ccc}
      $*$ & $\gr0$ & $\gr1$ & $\gr\omega$ \\ \hline
      $\gr0$ & $\gr0$ & $\gr0$ & $\gr0$ \\
      $\gr1$ & $\gr0$ & $\gr1$ & $\gr\omega$ \\
      $\gr\omega$ & $\gr0$ & $\gr\omega$ & $\gr\omega$ \\
    \end{tabular}
    \begin{tikzpicture}[baseline]
      \node(omega) at (0,0) {$\gr\omega$};
      \node(0) [above left of=omega] {$\gr0$};
      \node(1) [above right of=omega] {$\gr1$};

      \draw (omega) -- (0);
      \draw (omega) -- (1);
    \end{tikzpicture}
  }
\end{example}

%In \cref{sec:simple}, we saw that the logical rules of simply typed
%$\lambda$-calculus can be described in terms of three basic premise combinators:
%$\dot1$, standing for no premises; $\dottimes$, allowing for multiple premises
%in the same context; and $\Theta \vdash A$, requiring a subterm of type $A$
%having bound the extra variables from context $\Theta$.
%However, we remember from \cref{sec:linearity} that in a substructural setting,
%we do not always want to copy assumptions for use in all subterms.
%This motivates me to introduce the additional premise combinators $I^*$, $\sep$,
%and $\cdot$ in \cref{sec:lnd}, allowing for the modes of usage exhibited in
%the introduction rules for $I$, $\otimes$, and $\oc$, respectively.

The rest of this chapter proceeds as follows.
In \cref{sec:lr}, I define the usage-annotated calculus \name{}, which has
appeared in my previous work~\citep{WA21}, and can be seen as a
simply typed version of Atkey's dependently typed calculus QTT~\citep{Atkey18}.
The idea of \name{} is to augment the simply typed $\lambda$-calculus with
annotations on free variables, and give enough types to manipulate these
annotations.
Given this new calculus $\name$, the first goal is to apply the techniques of
\cref{sec:simple} to it, yielding a simultaneous substitution operation.
To do this, I use \cref{sec:lnd} to introduce notation that allows us to restate
the typing rules of \name{} to not mention contexts explicitly, as was the style
in \cref{sec:simple}.
This new notation --- the \emph{bunched connectives} --- is versatile at
defining simply typed usage-aware syntaxes, and I give further non-$\name$
examples in \cref{sec:rec}.
Finally, I justify connections to linear logic and modal logic in
\cref{sec:translation}, where I translate $\name$ terms to and from
DILL~\citep{Barber1996} and the modal calculus of \citet{judgmental}.
%The application of the techniques of \cref{sec:simple} is left to
%\cref{sec:ren-sub-lr}.

\section{A usage-annotated calculus $\name$}\label{sec:lr}
\input{lr.tex}
\section{Bunched connectives}\label{sec:lnd}
\input{lnd.tex}
\section{Additions to and variations of \name{}}\label{sec:variant}
\input{rec.tex}
\section{Translation to and from existing systems}\label{sec:translation}
\input{trans.tex}
\section{Addendum: (lack of) partiality}\label{sec:part}
\input{part.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Renaming and substitution for $\name$}\label{sec:ren-sub-lr}

In \cref{sec:semirings}, I defined my calculus of interest $\name$.
In this chapter, I develop the necessary syntactic metatheory for
specifying and implementing the substitution operation.
I follow the approach of \cref{sec:kits} using syntactic kits, but have to make
significant changes to the underlying notion of \emph{environment} before doing
so.
I give and informally motivate these changes to environments in
\cref{sec:lrkits}, and prove some properties of the new definition in
\cref{sec:lenv}.
Finally, I apply these new environments to the syntax of $\name$ in
\cref{sec:lrsub} to derive renaming and substitution operators.

\section{What are linear renaming and substitution?}\label{sec:lrkits}
\input{lrkits.tex}
\section{Properties of linear environments}\label{sec:lenv}
\input{lenv.tex}
\section{Substitution is admissible in \name{}}\label{sec:lrsub}
\input{lrsub.tex}
\section{Conclusion}\label{sec:ren-sub-lr-conc}

In the preceding two chapters, I have developed a discipline for specifying
the syntax of linear and modal type systems, and furthermore developing the
syntactic metatheory of those type systems.
All of these are based on semirings, and the linear algebra arising from
considering a usage context full of semiring elements as a vector.

These developments can be seen in retrospect as a generalisation of the methods
explained in \cref{sec:simple}.
In terms of premise connectives in the syntactic rules, we have generalised from
just $\{\dot1, \dottimes\}$ to
$\{\dot1, \dottimes, I^*, \sep, \gr r\cdot{}, \Box^{0{+}}\}$, maintaining our
ability to keep the context implicit.
Similarly to how rule premises can require separation of usage annotations, our
new environments can require such a separation between their entries thanks to
the linear map they now contain.
I have generalised the key property of a kit from arbitrary weakening to
weakening by $\gr0$-annotated variables, and using that have produced a
substitution operation based on the same principles as that from
\cref{sec:kits}.

Having generalised all of the components --- namely the contexts, the syntax,
and the notion of environment --- the type of the substitution operation looks
the same as it did for intuitionistic ST$\lambda$C\@.
Being able to maintain this uniformity is a key step towards generalising the
rest of \cref{sec:simple} (i.e., \cref{sec:gen-sem,sec:gen-syn}), as I do in
\cref{sec:framework}.

A similar substitution lemma appears in the PhD thesis of
\citet[p.\ 138]{petricek-thesis} under the name \emph{multi-nary substitution}.
In my notation, \citeauthor{petricek-thesis}'s substitution rule looks like the
following, up to permutation of the contexts containing $\Gamma$.
Note that if $\Delta = \grQ\delta$, then $\gr r\Delta$ denotes the context
$\plr{\gr r\grQ}\delta$.
This rule is essentially an iterated version of the standard linear single
substitution principle, and is used by \citeauthor{petricek-thesis} as a
strengthened induction hypothesis required to derive single substitution.

\[
  \ebrule{%
    \hypo{\Delta_1 \vdash A_1}
    \hypo{\cdots}
    \hypo{\Delta_n \vdash A_n}
    \hypo{\Gamma, \gr{r_1}A_1, \ldots, \gr{r_n}A_n \vdash B}
    \infer4{\Gamma, \gr{r_1}\Delta_1, \ldots, \gr{r_n}\Delta_n \vdash B}
  }
\]

We can derive \citeauthor{petricek-thesis}-style multi-nary substitution as a
corollary of my simultaneous substitution, using reasoning similar to that of
\cref{thm:single-sub}.

\begin{corollary}\label{thm:petricek-sub}
  \Citeauthor{petricek-thesis}'s multi-nary substitution, as stated above, is
  admissible in $\name$.
\end{corollary}
\begin{proof}
  It is enough to provide a substitution of type
  \[
    \Gamma, \gr{r_1}\Delta_1, \ldots, \gr{r_n}\Delta_n
    \env\vdash \Gamma, \gr{r_1}A_1, \ldots, \gr{r_n}A_n.
  \]
  To do this, we use \cref{thm:construct-env} repeatedly, leaving us needing a
  substitution of type
  $\Gamma, \gr0\Delta_1, \ldots, \gr0\Delta_n \env\vdash \Gamma$ and terms of
  types
  \begin{align*}
    \gr0\gamma, \Delta_1, \gr0\delta_2, &\ldots, \gr0\delta_{n-1}, \gr0\delta_n
    \vdash A_1 \\
    &\vdots \\
    \gr0\gamma, \gr0\delta_1, \gr0\delta_2, &\ldots, \gr0\delta_{n-1}, \Delta_n
    \vdash A_n.
  \end{align*}
  The identity substitution and weakening by $\gr0$-annotated variables is
  enough to make these requirements line up with the given hypotheses.
\end{proof}

My substitution principle is stronger than \citeauthor{petricek-thesis}'s.
Where \citeauthor{petricek-thesis} requires that distinct variables be
available for each hypothesis, I allow for separation of uses via addition of
contexts.
Below is a prototypical example.

\begin{example}
  Let $\Ann \coloneqq \plr{\mathbb N, =, 0, +, 1, \times}$, the exact
  usage-counting posemiring.
  Then, we can construct a substitution $\rho : \gr2A \env\vdash \gr1A, \gr1A$,
  yielding a transformation of terms of the following form:
  \[
    \ebrule{%
      \hypo{\gr1A, \gr1A \vdash B}
      \infer1{\gr2A \vdash B}
    }.
  \]
  To construct $\rho$, we use \cref{thm:construct-env} case
  $\sep(\rightarrowtriangle)$, using the fact that $\gr2 \leq \gr1 + \gr1$.
  From there, two identity substitutions suffice.
  The action of $\rho$ on terms is to merge the two variables into one.
  Note that a renaming, rather than a substitution, would also suffice.
\end{example}

Most notably, my (single) substitution principle more naturally fits the
requirement we would have for the reduct of the $\beta$-rule for functions in
$\name$, whereas \citeauthor{petricek-thesis}'s substitution principle would
need some additional transformation for it to fit properly.
This comes from the fact that the $\name$ function application rule introduces
an algebraic ($+$) separation between its premises, whereas
\citeauthor{petricek-thesis}'s substitution principle separates premises only
via concatenation.
