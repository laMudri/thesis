There is a vast literature on formalisations of syntaxes with binding, which I
cannot possibly do justice to in a reasonably sized thesis chapter.
Instead, I limit myself to comparisons of the \citet{AACMM21} method I follow in
this thesis to just its closest related work.

\subsection{Autosubst}

\citet{Autosubst15} present the system \emph{Autosubst}, which provides various
tools for working with syntaxes with binding in the Coq proof assistant.
Autosubst is based on similar ideas to those \citeauthor{AACMM21} use:
De Bruijn-indexed terms with a distinguished variable rule and notion of
binding, acted upon by simultaneous renaming and substitution.

The simplest differences are essentially matters of choosing the encoding that
best fits the proof assistant being used.
Coq users tend to prefer using unindexed types and propositions indexed over
them --- in this case, a type of unscoped and untyped terms plus a
``well typed'' predicate --- whereas Agda users prefer to work with only well
formed data (well scoped and well typed terms).
The latter approach more readily allows us to show generically that substitution
preserves scoping and typing, but the former approach, conversely, allows for
bespoke proofs of such facts.
For example, one theorem of \citet{Autosubst15} is type preservation for
$\mathrm{CC}_\omega$, a dependent type system we cannot express using the
machinery of \citet{AACMM21}.
In principle, one could use \citeauthor{AACMM21}'s machinery as the basis of a
similar bespoke proof, but as far as I am aware, this has not been tried.

Another main difference is that Autosubst is presented to the user largely as
a black-box implementation of substitution and related lemmas, in contrast to
\citeauthor{AACMM21}'s work exposing the \AgdaRecord{Semantics} bundle to the
user, and having substitution be just one instance.
\citet{ACMM17} and \citet{AACMM21} provide many examples of traversals over
syntax using the same generic environment management as used by substitution.
However, the focus on substitution in Autosubst has meant that reasoning about
substitutions has been given more developed support.
For example, the library provides a tactic \texttt{autosubst} which automates
many equational proofs involving substitutions based on the $\sigma$-calculus of
\citet{ACCL91}.

An interesting feature of Autosubst is \emph{heterogeneous substitution}.
The motivation for heterogeneous substitution is to handle systems like system
F, where types and terms are syntactically distinct, but both feature binding
and require a substitution operation.
Furthermore, binding and substitution of types also affects the syntax of terms,
thanks to $\Lambda$ terms.
\citeauthor{AACMM21} provide no direct equivalent to heterogeneous substitution,
and it is unclear how well their work can handle polymorphic calculi.

\citet{Autosubst18} propose some modifications to Autosubst which, as far as I
can tell, have not yet been incorporated, although all of the case studies in
the paper are mechanised in Coq.
In the paper, they adapt and extend the work of \citeauthor{ACMM17} on generic
semantic traversals to cover a variant of system F.
They use the term \emph{multivariate traversal} for the generalisation of
heterogeneous substitution to semantic traversals.
It appears that this work could be followed through to produce syntax
descriptions covering polymorphic calculi, which would provide a route for this
work to be incorporated into the Autosubst library.

\subsection{Second order abstract syntax}\label{sec:fiore}

Marcelo Fiore and various collaborators have a long line of work aiming for a
categorical account of variable-binding~\citep{FPT99,Fiore08,FH13,FH10,FM10}.
A recent, particularly relevant paper from this line of work is that of
\citet{FS22}, which mechanises some of this work to obtain a framework similar
in scope to the work of \citet{AACMM21}.
However, there are several differences between the resulting mechanised
frameworks, of methodological, mathematical, and technical nature.

Though \citet{AACMM21} did not state their results in categorical terms, it is
still useful to infer what the category-theoretic statement would have been, and
compare it to the statement actually given by \citet{FPT99} and \citet{FS22}.
When we do this, we see that while \citeauthor{FPT99} deal with the category of
contexts under renaming, and presheaves on that category.
This means that every model must be shown to respect renaming before touching
the framework of \citeauthor{FS22}.
Meanwhile, \citeauthor{AACMM21} make use of the interplay between the discrete
category of contexts and the category of contexts under renaming.
For example, the models (\AgdaRecord{Semantics}) of \citet{AACMM21} require only
that the family of semantic values $\V$ be shown to respect renaming, while the
fact that the result family $\C$ respects renaming follows as a corollary of the
traversal function \AgdaFunction{trav}.
\Citeauthor{FS22} make no distinction between $\V$ and $\C$, essentially only
having $\C$, but requiring it to respect renaming before getting the morphism
to that model from the initial model (the syntax).
In particular, this interplay allows us to derive renaming for terms in the way
we saw in \cref{sec:gen-syn} --- by making $\V$ the family of variables, which
trivially respects renaming.
%\todo{Every model is an environment model?}

Perhaps the relative complexity of the categorical account of the work of
\citet{AACMM21} is why the authors decided not to state it in such terms.
However, it is also likely that \citeauthor{AACMM21} developed their work in
quite a different style to how \citeauthor{FPT99} did, despite arriving at
similar theories.
The work of \citet{AACMM21} is designed first and foremost to facilitate
programming language mechanisations, and thus pays a lot of attention to syntax
and traversals of it, making sure that the results compute well in Agda.
On the other hand, \citeauthor{FPT99} started from theoretical investigations
about the category of models of theories with binding, and only applied their
work to the mechanisation of programming languages in the much later work of
\citet{FS22}.

In terms of the underlying theory, both works extend multi-sorted universal
algebra%\todo{cite}
with variable-binding.
However, the two extensions are subtly different.
Universal algebra already has a notion of variable, which supports renaming and
substitution, and which allows a given term to be evaluated when the free
variables of that term are assigned semantic values.
\citeauthor{AACMM21} reuse this notion of variable, and allow binding of such
variables in terms.
On the other hand, \citeauthor{FS22} recast the existing variables as
\emph{metavariables}, and introduce a new notion of (bindable) variables
separately into the syntax.
The resulting metavariables can then stand for arbitrary \emph{open} terms, and
thus each one remembers its context and requires an explicit substitution
whenever it is used.

%Compared to the work of \citet{AACMM21}, which is what I chose to guide this
%chapter and the rest of this thesis, \citet{FS22} can be understood as providing
%many extra features.
%I happened not to be interested in these specific features, so have not
%implemented them, but future development of the work I present in this thesis
%could benefit from such features.
%The extra features include an externally compiled language of syntax and theory
%descriptions, internal support for metavariables, and a treatment of the
%category of models (of which terms are the initial model and what I call
%\AgdaFunction{sem} forms the universal morphism from terms to any other model).

\Citeauthor{FS22} use metavariables to form descriptions of relations over
terms, like an equational theory over the simply typed $\lambda$-calculus.
Terms have, as well as their context of variables, a context of metavariables,
and terms can contain a metavariable wherever they could contain a subterm.
There is then an operation of metavariable substitution, which substitutes terms
in the place of metavariables.
Metavariable substitution is used to instantiate the rules of described
relations/theories.
In contrast, \citeauthor{AACMM21} make do with the variables of the metalanguage
(i.e.\ Agda variables).

More concrete work by \citet{MMS18}, building on the approach to semantics of
\citet{ACMM17} and \cref{sec:gen-sem}, also deals with syntactic contexts into
which terms can be substituted (as part of developing notions of contextual
equivalence).
However, this work makes use of several different notions of syntactic context,
rather than just the one given naturally by metavariables in the framework of
\citeauthor{FS22}.
This suggests that more research is needed about the various roles of
metavariables before any particular approach is standardised.

Technologically, \citeauthor{FS22} provide an external domain-specific language
for syntax descriptions.
From such a description, a Python program generates some boilerplate Agda code
providing the types, the algebraic signature, the well typed terms, and a proof
that the terms are the initial model.
Using code generation like this resembles parts of the Autosubst plugin, as
opposed to the purely internal, generic programming-based solution given by
\citeauthor{AACMM21} and in this thesis.

\Citet[p.\ 19]{FS22} avoid sized types by defining their equivalent of the
functorial mapping \AgdaFunction{map-s} specialised to \AgdaFunction{sem}, with
these two functions being mutually recursive.
This is a standard solution, where code reuse is traded away in favour of
satisfying the termination checker and avoiding sized types.

Despite all of these differences,
I chose to base the work of this thesis on that of \citet{AACMM21} for largely
circumstantial reasons.
I only became aware of the work of \citet{FS22} when it was published, by which
time I had already completed the bulk of the work presented in this thesis.
Also, one of the authors of the former paper is my PhD supervisor, and the other
authors too were working nearby, so it was easy to discuss their work quickly
and informally.
I think it is clear what it would mean to adapt the later work of this thesis to
a framework in the style of \citeauthor{FS22} rather than \citeauthor{AACMM21},
but it may not be obvious how usage restrictions (for ordinary variables) and
metavariables should interact.

\subsection{Substitution-based semantics}

A feature shared by the frameworks of \citet{AACMM21} and \citet{FPT99} (and
the rest of the work described in \cref{sec:fiore}) is that they are both often
concerned about how renamings act upon semantics/models.
The basic currency of both systems is presheaves on the category of contexts
under renaming, and when the user wants to produce a semantics, they must show
that the desired semantics forms such a presheaf --- amounting to showing that
the relevant type family respects renamings (in the direction that may introduce
new, unused variables to the context).

In contrast, the work of \citet{HHLM22} is based around the category of contexts
under \emph{substitution} or, more precisely, the morphisms given by semantic
environments of whatever semantics is being defined.
The focus on substitution makes this work simpler than renaming-based
frameworks, because we get to avoid talking about renaming, whereas we always
ultimately need to talk about substitution.
However, what is a gain for internal simplicity is a loss for usability.
For the syntax, starting from substitution means that the framework provides no
help in \emph{proving} the admissibility of substitution, because the syntax is
not considered a model \emph{until} we can show that it admits substitution.
Similarly, for semantic models, we have to prove that each model we consider
respects semantic substitution, which is a stronger requirement than
respecting renaming.

Additionally, \citet{HHLM22} gain further simplicity of definitions by not
keeping track of contexts.
For example, untyped substitutions on a set (as opposed to scope-indexed family)
$X$ are functions from $\mathbb N$ to $X$.
Similarly, the simply typed families introduced in section 6 of the
aforementioned paper are indexed on their type, but not their context.
Ignoring scopes/contexts lets one talk about monads (as in
\emph{De Bruijn monads}) rather than a more complex notion like relative
monads~\citep{ACU15}.
However, it also means losing potentially useful and important information.

\subsection{Nominal techniques}

There have been essentially two approaches when it comes to incorporating
nominal techniques into proof assistants.
The first is to develop a new foundational theory and develop a new proof
assistant on top of it.
The second is to take an existing proof assistant and provide a library,
possibly based on unsafe features.

The best-developed nominal foundational theory at the time of writing is
\emph{Fraenkel-Mostowski (FM) set theory}, as introduced by
\citet{Gabbay-thesis} and \citet{GP02}.
\citeauthor{Gabbay-thesis}'s thesis presents FM set theory, and then uses it as
the basis for a proof assistant Isabelle/FM and programming language FreshML\@.
FM is a variant of ZF set theory containing an infinite set $\mathbb A$ of
\emph{atoms} or \emph{names}, and the \emph{equivariance axiom}, stating that
every FM proposition is invariant under consistent permutation of $\mathbb A$.
In this setting, one can define the quantifier
$\reflectbox{$\mathsf N$}a.~\phi$,
read as introducing a \emph{new} or \emph{fresh} name $a$ to be used in the
proposition $\phi$.
As a material set theory, FM is unusual in that it refutes the axiom of choice.
In terms of applications to proof assistants, this means that FM is incompatible
with much existing Isabelle-based work, including anything using the Hilbert
$\varepsilon$-operator, which is used liberally in Isabelle/HOL\@.
For example, if the syntax of a programming language is formalised in FM, then
there is no formal connection to the kind of foundations in which interesting
denotational semantics have likely been formalised.

Related to nominal set theories is the recent work of \citet{Pitts23} about
theories of \emph{locally nameless sets}.
This behaves quite similarly to nominal theories, in that free variables have
names, and renaming is given by primitive operations.
In fact, \citet{Pitts23} shows that every locally nameless set is a nominal set.

The other approach --- implementing a nominal library within an existing proof
assistant --- is exemplified by the Nominal Isabelle library of \citet{Urban08}.
This work is based around having a countably infinite discrete type
\texttt{name} (which could be a type of natural numbers or strings, for example)
which is treated abstractly, and then defining liftings of permutations on
\texttt{name} to permutations on any other types involving \texttt{name}s.
Because these liftings are defined explicitly within Isabelle/HOL, the Nominal
Isabelle setup amounts to an explicit model of a nominal logic within
Isabelle/HOL\@.
This setup resembles what \citet{AACMM21} did within Agda, and similarly what I
do later in this thesis --- creating a library within an existing proof
assistant.
The main downside, compared to working internally to a nominal set theory, is
that the external constructions of Nominal Isabelle are more complicated, and
involve keeping track of more properties that do not come as part of the theory
the proof assistant understands.

There has also been an effort to replicate the Nominal Isabelle work in Coq by
\citet{ABW06}.
However, this work appears to have been abandoned before publication, and the
approach is unclear from the work-in-progress paper.
Nominal libraries have also been made in general-purpose programming languages,
like in Haskell with the nom package~\citep{Gabbay20}.

From a broader perspective, I claim that nominal techniques solve a subtly
different problem to that solved by the likes of Autosubst, the work of Fiore,
and the techniques discussed in detail in this chapter.
The names found in nominal techniques are more general than (names of)
variables in formal systems.
This means that nominal techniques have been applicable to problems outside
standard programming language theory, such as in the representation of graphs
and in topology~\citep{GG17}.
However, in certain ways, this is arguably not a good fit for type systems.
In a basic nominal formalisation of a syntax with binding, there is no real
distinction between the context of a term and the collection of that term's free
variables.
This, for example, leaves no natural place to put the types of variables, except
as either a partial function from the set of names to types, or from the
computed set of free variables to types.
The discrepancy becomes even more apparent in substructural systems, as we see
later, where we want tight control over the context, as opposed to the scope.

\subsection{Logical frameworks}\label{sec:lf}

Logical frameworks based on higher order abstract syntax are another approach
which has been used to mechanise the metatheory of logics and programming
languages.
Primary among logical frameworks in recent study is the Edinburgh Logical
Framework~\citep{HHP93}, also known as \emph{LF}.
The underlying theory of LF is a dependent type theory $\lambda^\Pi$ featuring
\emph{weak} function spaces.
Weak function spaces differs from the usual strong function spaces in that
functions in a weak function space cannot inspect their arguments --- only
place them whole in their result.
Therefore, variables of the logical framework can be used as if they were the
variables of the object language.

Below I give two example constructors of a type family $\mathrm{tm}$.
These declarations are similar to the rule descriptions I gave in
\cref{fig:app-lam} for their lack of explicit contexts.
In this example, $\Pi$ is the type former for dependent weak function spaces,
with $\to$ being the non-dependent specialisation of $\Pi$.
The quoted arrow $\qto$ is a type former of the object language, as in the
previous examples in this chapter.

\begin{align*}
  \mathrm{lam} &: \Pi A,B.~\plr{\mathrm{tm}\,A \to \mathrm{tm}\,B} \to
                 \mathrm{tm}\,\plr{A \qto B} \\
  \mathrm{app} &: \Pi A,B.~\mathrm{tm}\,\plr{A \qto B} \to
                 \mathrm{tm}\,A \to \mathrm{tm}\,B
\end{align*}

Like several other approaches I have described in this chapter, logical
frameworks aim to manage variables, variable binding, and contexts in a generic
way, giving the user only the choice of what logical rules they want to add to a
basic calculus.
In fact, logical frameworks go further than any other approach I have described,
never giving the user reified access to the context of object language terms,
and giving immediate access to (single) substitution simply as application of
weak functions.
LF also natively supports more complex calculi than the simply typed
$\lambda$-calculus --- for example allowing us to implement and reason about
System F.

The main drawback of logical frameworks is that making one requires making a new
proof assistant, typically with no compatibility with existing proof assistants
and their libraries of useful mathematical definitions and proofs.
Particularly, if you want to consider calculi not (conveniently) expressible in
$\lambda^\Pi$ (as I do, with substructural calculi), then you need to make a new
logical framework which is probably also incompatible with existing logical
frameworks.
As such, no single logical framework acts as a convenient and natural foundation
upon which to build a broad range of mathematics including substructural logics
and their metatheory.
