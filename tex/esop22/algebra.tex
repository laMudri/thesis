The basic algebraic structure we concern ourselves with is \emph{partially
ordered semirings}, or \emph{posemirings} for short.
A posemiring is a (not necessarily commutative) semiring on a partially ordered
set, where both operations are monotonic.

\begin{definition}
  A \emph{posemiring} is a tuple $(\Ann, \leq, 0, +, 1, *)$ such that the
  following laws hold (universally quantified in all the variables).
  \begin{itemize}
    \item $x \leq x' \to y \leq y' \to x + y \leq x' + y'$
    \item $x \leq x' \to y \leq y' \to x * y \leq x' * y'$
    \item $0 + x = x
      \land x + 0 = x
      \land (x + y) + z = x + (y + z)
      \land x + y = y + x$
    \item $1 * x = x
      \land x * 1 = x
      \land (x * y) * z = x * (y * z)$
    \item $0 * x = 0
      \land (x + y) * z = x * z + y * z$
    \item $x * 0 = 0
      \land x * (y + z) = x * y + x * z$
  \end{itemize}
\end{definition}

An element of a chosen posemiring $\Ann$ describes the usage restrictions on
a variable.
Therefore, a \emph{vector} of elements from $\Ann$ describes the usage
restrictions of a whole context's worth of variables.
From the posemiring operations of $\Ann$, we derive the standard vector
operations of zero, addition, and multiplication by a scalar.
We can also form the standard basis vectors at any given dimension.

Vectors of a given length form a \emph{module} over the posemiring $\Ann$,
analogously to how vectors over a field form a vector space.

\begin{definition}
  A \emph{(left) module over a posemiring}, given a posemiring $\Ann$, is a
  partially ordered commutative monoid $(M, 0_M, +_M)$ with, for each
  $r \in \Ann$, a pomonoid morphism $r \cdot \plr{-} : M \to M$, such that the
  collection of these respects the posemiring structure on $r$.
  Specifically:
  \begin{itemize}
    \item $r \leq r' \to u \leq u' \to r \cdot u \leq r' \cdot u'$
    \item $r \cdot 0_M = 0_M
      \land r \cdot \plr{u +_M v} = r \cdot u +_M r \cdot v$
    \item $0 \cdot u = 0_M
      \land \plr{r + s} \cdot u = r \cdot u +_M s \cdot u$
    \item $1 \cdot u = u
      \land \plr{r * s} \cdot u = r \cdot \plr{s \cdot u}$
  \end{itemize}
\end{definition}

We care to define modules so as to define \emph{module morphisms}, also known
as \emph{linear maps}, which we use extensively when relating two contexts (as
we do, for example, in simultaneous substitution).
For the sake of mechanisation, we choose to define module morphisms
\emph{relationally} rather than \emph{functionally}, giving a somewhat
unfamiliar-looking definition that is equivalent to the usual functional
definition.
The main advantage of this relational approach is that proofs of relatedness
for typical linear maps compose and decompose via data constructors and
pattern matching.
% I'm not sure this is a real difference:
%An auxiliary advantage is that with relations rather than functions, we can
%much more often take advantage of judgemental injectivity, thus making
%unification-based solving of implicits more effective.
%For example, if \AgdaBound{R} is a free variable of relation type, then
%\AgdaInductiveConstructor{refl} serves as a proof of
%\ExecuteMetaData[\Snippetstex]{Rxy-R}{}, solving the underscores as
%\AgdaBound{x} and \AgdaBound{y}, respectively.

\begin{definition}
  A \emph{(relational) linear map} $\Psi$ between modules $M$ and $N$ over a
  posemiring $\Ann$ is a relation $\sim$ on the underlying sets of $M$ and $N$
  satisfying the following laws.
  \begin{itemize}
    \item $u \leq u' \to v' \leq v \to u \sim v \to u' \sim v'$
    \item $\forall v.~\plr{\exists u.~u \leq 0 \land u \sim v} \to v \leq 0$
    \item $\forall u_0,u_1,v.~\plr{\exists u.~u \leq u_0 + u_1 \land u \sim v}
      \to {}$\\$\plr{\exists v_0,v_1.~u_0 \sim v_0
      \land u_1 \sim v_1 \land v \leq v_0 + v_1}$
    \item $\forall r,u',v.~\plr{\exists u.~u \leq ru' \land u \sim v} \to
      \plr{\exists v'.~u' \sim v' \land v \leq rv'}$
    \item
      $\forall u.~\exists v.~u \sim v \land \forall v'.~u \sim v' \to v' \leq v$
  \end{itemize}
\end{definition}

Intuitively, $Q \sim P$, where $P$ and $Q$ are row vectors, is equivalent to
$P \leq Q\Psi$, where $\Psi$ is the matrix representing the linear map and on
the right is a vector-matrix multiplication.
It is important that we think of \emph{row} vectors and
\emph{right}-multiplication by a matrix because, without commutativity of the
underlying posemiring, we can only expect $\plr{rQ}\Psi = r\plr{Q\Psi}$ and
not $\Psi\plr{rQ} = r\plr{\Psi Q}$.
In \cref{sec:env}, we use the matrix notation for convenience, while in the
Agda code we see \ExecuteMetaData[\Snippetstex]{Psi-rel-P-Q}.

\begin{figure}
  \begin{align*}
    \dot1\,\grR &\coloneqq 1 \\
    (T \dottimes U)\,\grR &\coloneqq T\,\grR \times U\,\grR \\
    (T \dotto U)\,\grR &\coloneqq T\,\grR \to U\,\grR \\
    I^*\,\grR &\coloneqq \grR \leq \gr0 \\
    (T \sep U)\,\grR &\coloneqq \Sigma \grP,\grQ.~\plr{\grR \leq \grP + \grQ}
                       \times T\,\grP \times U\,\grQ \\
    (\gr r \cdot T)\,\grR &\coloneqq \Sigma \grP.~\plr{\grR \leq \gr r\grP}
                       \times T\,\grP \\
    (T \wand U)\,\grP &\coloneqq \Pi \grQ,\grR.~\plr{\grR \leq \grP + \grQ}
                       \to T\,\grQ \to U\,\grR
  \end{align*}
  \caption{The bunched connectives}
  \label{fig:bunched}
\end{figure}

%Operations like renaming and substitution are essentially translations from one
%context to another.
%When faced with two vector spaces arranged in this way, a natural thing to
%consider is the \emph{linear maps} from one space to the other.
