The main use I have for Agda in this thesis is to represent and reason about
programming languages.
In particular, I am interested in representing \emph{core languages} or
\emph{core calculi}.
Given a standard multi-pass compiler, the core language can be identified as the
first stage after which there can be no compile-time errors.
In other words, (some) terms of the core language arise from taking the source
code for a term, parsing it, scope-checking it, type-checking it, and doing
whatever other static checks are done to it.
Core language terms can also arise via optimisations on other core language
terms, or could not actually appear in the compilation of any real program, but
nonetheless be potentially handled by the optimiser and backend.
The core language can also be thought of as a representation of the
\emph{meaningful} part of a programming language, excluding (meaningless)
erroneous programs.

In most compilers, the core language is represented as an annotated abstract
syntax tree.
By construction, the abstract syntax tree representation makes syntactically
ill formed programs unrepresentable.
When representing a core language in a dependently typed language, including
Agda, we can take this idea further to make ill scoped, ill typed, and otherwise
meaningless programs unrepresentable.
Thus, we can truly \emph{define} a core language, and moreover reason
mathematically about it.

As is standard in the study of functional programming languages, I will take the
core languages I consider to be variants of the simply typed
$\lambda$-calculus~\citep{Church40,Barendregt93}.
As part of the Curry-Howard correspondence~\citep{Howard80}, terms of a typed
$\lambda$-calculus correspond to derivations in a natural deduction system, and
therefore we can take inspiration in terms of definitions and methodology from
logic when we come to mechanise core calculi in Agda.
We could mechanise Gentzen's original definition of a natural deduction system
directly, but this definition is quite complicated.
In particular, if we want to give derivations an inductive definition, the use
of the discharge mechanism means that we actually need an inductive-inductive
type --- derivations, particularly those using $\to$-introduction, can involve
references to assumptions within their subderivations.
An inductive-inductive definition of derivations would complicate our programs
and proofs about natural deduction derivations, so I choose an alternative
representation.

Indeed, most authors since Gentzen, whether mechanising their work or not,
have opted to replace discharge of assumptions by explicit \emph{contexts} and
a variable rule.
Contexts can be justified as a way to keep track of undischarged assumptions.
In particular, we only produce derivations in the presence of a known collection
of \emph{free variables} specified by the context.
In other words, derivations are \emph{indexed} over their free variables and
their types.
When using an assumption within a derivation, we must say which free variable
it corresponds to.
Free variables are introduced by \emph{variable-binding} rules, like
$\to$-introduction.
\Cref{fig:explicit-contexts} gives an example of the same derivation written
in Gentzen's style and in the explicit context style.

\begin{sidewaysfigure}
  \centering
  \begin{prooftree}
    \hypo{[A \to A \to B]^f}
    \hypo{[A]^x}
    \infer2[$\to$-E]{A \to B}
    \hypo{[A]^x}
    \infer2[$\to$-E]{B}
    \infer1[$\to$-I$^x$]{A \to B}
    \infer1[$\to$-I$^f$]{\plr{A \to A \to B} \to \plr{A \to B}}
  \end{prooftree}

  \vspace{2em}

  \begin{prooftree}
    \infer0[var$^f$]{{\color{red}f : A \to A \to B, x : A} \vdash A \to A \to B}
    \infer0[var$^x$]{{\color{red}f : A \to A \to B, x : A} \vdash A}
    \infer2[$\to$-E]{{\color{red}f : A \to A \to B, x : A} \vdash A \to B}
    \infer0[var$^x$]{{\color{red}f : A \to A \to B, x : A} \vdash A}
    \infer2[$\to$-E]{{\color{red}f : A \to A \to B, x : A} \vdash B}
    \infer1[$\to$-I$^x$]{{\color{red}f : A \to A \to B} \vdash A \to B}
    \infer1[$\to$-I$^f$]{\vdash \plr{A \to A \to B} \to \plr{A \to B}}
  \end{prooftree}
  \caption{A proof in Gentzen's natural deduction syntax, and a proof using
    explicit contexts (contexts coloured {\color{red}red})}
  \label{fig:explicit-contexts}
\end{sidewaysfigure}

Explicit contexts can be seen as a mechanism for encoding a natural deduction
system as a sequent calculus.
However, the natural deduction character of the system is maintained by
ensuring that the resultant sequent calculus is really an encoding of a
natural deduction system.
Concretely, this means that rules can only interact with the context in
restricted ways:

\begin{itemize}
  \item There is a designated \emph{variable rule}, stating that any variable
    in the context can serve as a derivation of its type.
  \item Non-variable rules may only require subterms with \emph{extended}
    contexts, i.e., subterms in which new variables have been bound.
    Non-variable rules are parametric in the existing free variables.
\end{itemize}

Having chosen to use explicit contexts, the mechanisation must have a chosen
representation of contexts as a data structure.
While the notation in \cref{fig:explicit-contexts} uses names $f$ and $x$
for variables, I opt for a nameless representation.
In a nameless representation, variables are identified by their position in
the context, rather than by a name.
The absence of names means that $\alpha$-equivalence is just on-the-nose
equality, and also that we never have to reason about freshness of names.
Agda does not have support for nominal techniques~\citep{GP02}, which may have
made names a better option.

Most mechanisations choose contexts to be an inductive list of object-language
types.
However, I instead choose a functional, tree-shaped representation, as shown
with the type \AgdaRecord{Ctx}.
The type \AgdaDatatype{LTree} is the inductive type generated by
leaves (\AgdaInductiveConstructor{[-]}) and
nullary (\AgdaInductiveConstructor{$\upvarepsilon$}) \&
binary (\AgdaInductiveConstructor{\_<+>\_}) nodes, and serves as a generalised
``length'' of the context.
The tree shape makes concatenation definitionally
injective, so that in cases where multiple new variables are bound in a subterm
(for example, $\otimes$-elimination), Agda's unification-based solving will
be more able to infer which variables have just been bound.
Within a given \AgdaBound{t}\AgdaSpace{}\AgdaSymbol:\AgdaSpace{}%
\AgdaDatatype{LTree}, we can define the positions of \AgdaBound{t} using
\AgdaDatatype{Ptr}.
A \emph{pointer} (\AgdaDatatype{Ptr}) into a tree picks out a leaf
(\AgdaInductiveConstructor{[-]}) following a path of lefts
(\AgdaInductiveConstructor{$\swarrow$}) and rights
(\AgdaInductiveConstructor{$\searrow$}) at any binary nodes encountered.

\ExecuteMetaData[\LTreetex]{LTree}
\ExecuteMetaData[\LTreetex]{Ptr}

I use \AgdaDatatype{Ptr} to form a type family of \AgdaDatatype{LTree}-indexed
vectors \AgdaFunction{Vector}.
These vectors serve as the data structure containing the types, and in later
chapters usage information, of contexts.
The advantages of the functional vector representation will not become clear
until later chapters --- particularly the example in
\cref{sec:usage-elaborator}, where I make use of the ease of look-up and the
$\eta$-law of functions.
However, I claim for now that there is little to no disadvantage in the
functional vector representation --- in particular, we have no need for
function extensionality principles because we never talk about equality of
contexts.
For example, instead of using an equality of contexts to coerce a term, we can
use renaming.

\ExecuteMetaData[\Vectortex]{Vector}

The basic operations for building vectors from parts are \AgdaFunction{[\_]} to
create a singleton vector, \AgdaFunction{[]} to create an empty vector, and
\AgdaFunction{\_++\_} to append two vectors.

The shape of the context is usually not worth indexing over in term
representation, so I hide this index using the record type \AgdaRecord{Ctx}.
I also instantiate the element type of these vectors to \AgdaDatatype{Ty}, the
type of object-language types.

\Ctx{}

The three operators for building vectors lift to operations on \AgdaRecord{Ctx}
by suffixing \AgdaFunction{$^c$} --- giving us \AgdaFunction{[\_]$^c$},
\AgdaFunction{[]$^c$}, and \AgdaFunction{\_++$^c$\_}.

Our first data structure involving contexts is that of intrinsically typed
variables.
A variable of type
\AgdaBound{$\Gamma$}\AgdaSpace{}\AgdaRecord{$\ni$}\AgdaSpace{}\AgdaBound{A}
is given by a path \AgdaField{idx} to a type in \AgdaBound{$\Gamma$}, together
with a proof \AgdaField{tyq} that this type is equal to \AgdaBound{A}.

\Var{}

Variables embed into terms via the \AgdaInductiveConstructor{var} constructor of
the family \AgdaDatatype{\_⊢\_} of intrinsically simply typed terms.
The only other syntactic forms we consider for now are the eliminator and
constructor of function types \AgdaInductiveConstructor{\_`→\_} ---
\AgdaInductiveConstructor{app} and \AgdaInductiveConstructor{lam}.
Application \AgdaInductiveConstructor{app} takes two subterms of the appropriate
types, while the subterm of $\lambda$-abstraction \AgdaInductiveConstructor{lam}
is in an extended context \GA{} --- \AgdaBound{$\Gamma$} concatenated with a
singleton context containing the type \AgdaBound{A}.

\Term{}

Using this encoding, the Church numeral for 2 appears as follows.
In standard notation, this would be
$\lambda f.~\lambda x.~f\,(f\,x)$.
To refer to $f$ in the main body of the expression, we skip one binder (using
\AgdaInductiveConstructor{$\swarrow$}) and pick the next one
(using \AgdaInductiveConstructor{$\searrow$}) and pick its only bound variable
(using \AgdaInductiveConstructor{here}).
To refer to $x$, we do not skip its binder, instead picking it and its only
bound variable.

\ExecuteMetaData[../agda/processed-latex/SimpleKits.tex]{two}
